{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstractive Summarisation LSTM+Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR03IMFqLmeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d7634b7c-1f91-482a-c829-9f651b8b730b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1jpd5dLssg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UVnQqjTLszo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ea2fd91-0998-403c-839a-32047cda4d1d"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\t  Reviews.csv\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   kindle_reviews.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRBwwvAzLs34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f818934c-c2fa-441c-e887-042dc6ec822e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras import backend as K\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSrQBWr1Ls7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "9b317adc-c5ca-4903-f685-5f545c2d39b3"
      },
      "source": [
        "# Read the Data\n",
        "data1 = pd.read_csv('Reviews.csv')\n",
        "print(data1.columns)\n",
        "#remove uneccessary columns \n",
        "data1 = data1.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
        "       'HelpfulnessDenominator', 'Score', 'Time'], axis = 1)\n",
        "print(\"Removed unecessary columns\")\n",
        "for i in range(5):\n",
        "  print(data1.Text[i])\n",
        "  print(data1.Summary[i])\n",
        "  print('\\n')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
            "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "Removed unecessary columns\n",
            "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
            "Good Quality Dog Food\n",
            "\n",
            "\n",
            "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
            "Not as Advertised\n",
            "\n",
            "\n",
            "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
            "\"Delight\" says it all\n",
            "\n",
            "\n",
            "If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
            "Cough Medicine\n",
            "\n",
            "\n",
            "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
            "Great taffy\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRw6kdY9Ls-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "591d9917-9ba9-47f9-e16c-1e056052bd65"
      },
      "source": [
        "# Read the Data\n",
        "data2 = pd.read_csv('kindle_reviews.csv')\n",
        "print(data2.columns)\n",
        "#remove uneccessary columns \n",
        "data2 = data2.drop(['Unnamed: 0', 'asin', 'helpful', 'overall','reviewTime', \n",
        "        'reviewerID', 'reviewerName','unixReviewTime'], axis = 1)\n",
        "print(\"Removed unecessary columns\")\n",
        "data2.rename(index = str, columns = {'summary':'Summary', 'reviewText':'Text'}, inplace = True)\n",
        "data2 = data2[['Summary','Text']]\n",
        "# print(data2.head())\n",
        "for i in range(5):\n",
        "  print(data2.Text[i])\n",
        "  print(data2.Summary[i])\n",
        "  print('\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'asin', 'helpful', 'overall', 'reviewText', 'reviewTime',\n",
            "       'reviewerID', 'reviewerName', 'summary', 'unixReviewTime'],\n",
            "      dtype='object')\n",
            "Removed unecessary columns\n",
            "I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\n",
            "Nice vintage story\n",
            "\n",
            "\n",
            "This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\n",
            "Different...\n",
            "\n",
            "\n",
            "This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\n",
            "Oldie\n",
            "\n",
            "\n",
            "I'd never read any of the Amy Brewster mysteries until this one..  So I am really hooked on them now.\n",
            "I really liked it.\n",
            "\n",
            "\n",
            "If you like period pieces - clothing, lingo, you will enjoy this mystery.  Author had me guessing at least 2/3 of the way through.\n",
            "Period Mystery\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw3PQ3LqLtCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8f4dae22-335c-47ef-8e74-b9eb6eecacbd"
      },
      "source": [
        "data = pd.concat([data2, data1])\n",
        "print(data.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Summary                                               Text\n",
            "0  Nice vintage story  I enjoy vintage books and movies so I enjoyed ...\n",
            "1        Different...  This book is a reissue of an old one; the auth...\n",
            "2               Oldie  This was a fairly interesting read.  It had ol...\n",
            "3  I really liked it.  I'd never read any of the Amy Brewster mysteri...\n",
            "4      Period Mystery  If you like period pieces - clothing, lingo, y...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2opkXRcgLtFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "17abf4e3-2e18-49ea-fd2e-93be61244a20"
      },
      "source": [
        "#checking for any empty data\n",
        "print(\"Checking for empty data: \")\n",
        "print(data.isnull().sum())\n",
        "print('\\n')\n",
        "#remove any empty data \n",
        "data = data.dropna()\n",
        "data = data.reset_index(drop = True)\n",
        "\n",
        "#checking if the empty data has been deleted\n",
        "print(\"Checking again for empty data: \")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking for empty data: \n",
            "Summary    28\n",
            "Text       22\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "Checking again for empty data: \n",
            "Summary    0\n",
            "Text       0\n",
            "dtype: int64\n",
            "              Summary                                               Text\n",
            "0  Nice vintage story  I enjoy vintage books and movies so I enjoyed ...\n",
            "1        Different...  This book is a reissue of an old one; the auth...\n",
            "2               Oldie  This was a fairly interesting read.  It had ol...\n",
            "3  I really liked it.  I'd never read any of the Amy Brewster mysteri...\n",
            "4      Period Mystery  If you like period pieces - clothing, lingo, y...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q182Sk3LtMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#expand common contractions inside the text\n",
        "contraction_expander = { \n",
        "\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'll\": \"how will\",\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\"i'll\": \"i will\",\"i'm\": \"i am\",\"i've\": \"i have\", \"isn't\": \"is not\",\"it'd\": \"it would\",\"it'll\": \"it will\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"needn't\": \"need not\",\"oughtn't\": \"ought not\",\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\"she'd\": \"she would\", \"she'll\": \"she will\",\"she's\": \"she is\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\"that'd\": \"that would\", \"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'll\": \"they will\", \"they're\": \"they are\",\"they've\": \"they have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "\"we'll\": \"we will\",\"we're\": \"we are\",\"we've\": \"we have\",\"weren't\": \"were not\",\"what'll\": \"what will\",\"what're\": \"what are\",\"what's\": \"what is\", \"what've\": \"what have\",\n",
        "\"where'd\": \"where did\",\"where's\": \"where is\",\"who'll\": \"who will\",\"who's\": \"who is\", \"won't\": \"will not\",\"wouldn't\": \"would not\",\"you'd\": \"you would\",\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\"\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmRaYkBoLtQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "0fcf7998-64fb-4a0e-c3f3-9661fa30400e"
      },
      "source": [
        "#function to clean the text and summary\n",
        "stop_words = set(stopwords.words('english')) \n",
        "def content_cleaner(content, remove_stop_words=True):\n",
        "    text = content.lower()\n",
        "\n",
        "    #expand the contractions\n",
        "    expanded_form = []\n",
        "    for i in text.split():\n",
        "      if i in contraction_expander:\n",
        "        expanded_form = expanded_form + [contraction_expander[i]]\n",
        "      else:\n",
        "        expanded_form = expanded_form + [i]\n",
        "    text = ' '.join(expanded_form)\n",
        "\n",
        "    #remove the punctuations\n",
        "    regex = re.compile('[%s]' % re.escape(string.punctuation))         \n",
        "    text = regex.sub(\" \", text)\n",
        "    \n",
        "    #whitespace\n",
        "    text = re.sub('\\s+', ' ', text).strip()  \n",
        "\n",
        "    #stopwords removal\n",
        "    if remove_stop_words:\n",
        "        remove = [i for i in text.split() if not i in stop_words]  \n",
        "        text = (\" \".join(remove)).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "#clean the text and append into an array\n",
        "clean_texts = []\n",
        "for text in data.Text:\n",
        "    clean_texts.append(content_cleaner(text,remove_stop_words=True))\n",
        "print(\"Text Appended.\")\n",
        "\n",
        "#clean the summary and append into an array\n",
        "clean_summaries = []\n",
        "for summary in data.Summary:\n",
        "    clean_summaries.append(content_cleaner(summary,remove_stop_words=False))\n",
        "print(\"Summaries Appended.\")\n",
        "\n",
        "#checking \n",
        "for i in range(3):\n",
        "  print(\"Text:\\n\", clean_texts[i])\n",
        "  print(\"Summary:\\n\", clean_summaries[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Appended.\n",
            "Summaries Appended.\n",
            "Text:\n",
            " enjoy vintage books movies enjoyed reading book plot unusual think killing someone self defense leaving scene body without notifying police hitting someone jaw knock would wash today still good read\n",
            "Summary:\n",
            " nice vintage story\n",
            "Text:\n",
            " book reissue old one author born 1910 era say nero wolfe introduction quite interesting explaining author forgotten would never heard language little dated times like calling gun 34 heater 34 also made good use fire dictionary look words like 34 deshabille 34 34 canarsie 34 still well worth look see\n",
            "Summary:\n",
            " different\n",
            "Text:\n",
            " fairly interesting read old style terminology glad get read story coarse crasslanguage read fun relaxation like free ebooksbecause check writer decide intriguing innovative enough command englishthat convey story without crude language\n",
            "Summary:\n",
            " oldie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6zRKA3YLtZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "404eeb4b-e1e3-476c-ff76-d0c4d7e89738"
      },
      "source": [
        "#see the distirbution\n",
        "def distribution_length(text):\n",
        "    lengths = []\n",
        "    for sentence in text:\n",
        "        lengths.append(len(sentence))\n",
        "    return pd.DataFrame(lengths, columns=['counts'])\n",
        "\n",
        "lengths_summaries = distribution_length(clean_summaries)\n",
        "lengths_texts = distribution_length(clean_texts)\n",
        "\n",
        "print(\"Describe Summaries:\")\n",
        "print(lengths_summaries.describe())\n",
        "print('\\n')\n",
        "print(\"Describe Texts:\")\n",
        "print(lengths_texts.describe())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Describe Summaries:\n",
            "             counts\n",
            "count  1.551023e+06\n",
            "mean   2.211637e+01\n",
            "std    1.479597e+01\n",
            "min    0.000000e+00\n",
            "25%    1.200000e+01\n",
            "50%    1.800000e+01\n",
            "75%    2.900000e+01\n",
            "max    2.490000e+02\n",
            "\n",
            "\n",
            "Describe Texts:\n",
            "             counts\n",
            "count  1.551023e+06\n",
            "mean   3.314817e+02\n",
            "std    3.977787e+02\n",
            "min    0.000000e+00\n",
            "25%    1.080000e+02\n",
            "50%    1.930000e+02\n",
            "75%    3.830000e+02\n",
            "max    1.490900e+04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5XZqQj2LtYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ad942f42-d27a-49af-fc22-2fe48490a1ec"
      },
      "source": [
        "#checking lengths\n",
        "count_text = 0\n",
        "for i in clean_texts:\n",
        "    if(len(i.split()) >= 10):\n",
        "        count_text = count_text + 1\n",
        "print(\"Minimum Text: \")\n",
        "print(count_text/len(clean_texts))\n",
        "\n",
        "count_summary = 0\n",
        "for i in clean_summaries:\n",
        "    if(len(i.split()) >= 5):\n",
        "        count_summary = count_summary + 1\n",
        "print(\"Minimum Summary: \")\n",
        "print(count_summary/len(clean_summaries))\n",
        "            \n",
        "count_text = 0\n",
        "for i in clean_texts:\n",
        "    if(len(i.split()) <= 90):\n",
        "        count_text = count_text + 1\n",
        "print(\"Maximum Text: \")\n",
        "print(count_text/len(clean_texts))\n",
        "\n",
        "count_summary = 0\n",
        "for i in clean_summaries:\n",
        "    if(len(i.split()) <= 8):\n",
        "        count_summary = count_summary + 1\n",
        "print(\"Maximum Summary: \")\n",
        "print(count_summary/len(clean_summaries))\n",
        "            "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Text: \n",
            "0.9702377076290938\n",
            "Minimum Summary: \n",
            "0.3366887531648467\n",
            "Maximum Text: \n",
            "0.8796916615678814\n",
            "Maximum Summary: \n",
            "0.9253931115141426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpqeetXULtVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a9be6eb-6c5b-4bbe-db33-2ed23daf5261"
      },
      "source": [
        "#place limitations on data due to computational limitations\n",
        "minimum_text_length = 10\n",
        "maximum_text_length = 90\n",
        "minimum_summary_length = 3\n",
        "maximum_summary_length = 8\n",
        "\n",
        "#arrays to store summaries & texts that fit the requirements\n",
        "accepted_summaries = []\n",
        "accepted_texts = []\n",
        "\n",
        "for i in range(len(clean_texts)):\n",
        "  if(len(clean_summaries[i].split())>=minimum_summary_length and len(clean_summaries[i].split())<=maximum_summary_length and\n",
        "        len(clean_texts[i].split()) >=minimum_text_length and len(clean_texts[i].split())<=maximum_text_length ):\n",
        "    accepted_summaries.append(clean_summaries[i])\n",
        "    accepted_texts.append(clean_texts[i])\n",
        "\n",
        "#length of summaries and text\n",
        "print(\"Summaries:\", len(accepted_summaries))\n",
        "print(\"Text:\", len(accepted_texts))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summaries: 749310\n",
            "Text: 749310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JYLpS_fLtT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7c2864c1-d742-4585-d0e1-cfa7fc9be661"
      },
      "source": [
        "#see the distirbution of the accepted text and summaries\n",
        "lengths_accepted_summaries = distribution_length(accepted_summaries)\n",
        "lengths_accepted_texts = distribution_length(accepted_texts)\n",
        "\n",
        "print(\"Describe Summaries:\")\n",
        "print(lengths_accepted_summaries.describe())\n",
        "print('\\n')\n",
        "print(\"Describe Texts:\")\n",
        "print(lengths_accepted_texts.describe())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Describe Summaries:\n",
            "              counts\n",
            "count  749310.000000\n",
            "mean       24.076153\n",
            "std         8.856892\n",
            "min         5.000000\n",
            "25%        17.000000\n",
            "50%        22.000000\n",
            "75%        30.000000\n",
            "max        77.000000\n",
            "\n",
            "\n",
            "Describe Texts:\n",
            "              counts\n",
            "count  749310.000000\n",
            "mean      226.967680\n",
            "std       136.036538\n",
            "min        27.000000\n",
            "25%       116.000000\n",
            "50%       189.000000\n",
            "75%       309.000000\n",
            "max       748.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cP5MKquMCaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add tokens at the begining and the end of the summaries\n",
        "accepted_summaries = list(map(lambda x: 'starttoken '+ x + ' endtoken', accepted_summaries))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPQK3Bk4MCnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_train,text_val,summary_train, summary_val = train_test_split(np.array(accepted_texts),np.array(accepted_summaries), test_size = 0.2, random_state=0)\n",
        "\n",
        "#tokenizer for text \n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(text_train))\n",
        "\n",
        "count = 0\n",
        "for i in x_tokenizer.word_counts.items():\n",
        "  count = count + 1\n",
        "\n",
        "#tokenizer for text \n",
        "x_tokenizer = Tokenizer(num_words = count)\n",
        "x_tokenizer.fit_on_texts(list(text_train))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "text_train = x_tokenizer.texts_to_sequences(text_train)\n",
        "text_val = x_tokenizer.texts_to_sequences(text_val)\n",
        "\n",
        "#ensures all sequences in the list have the same length\n",
        "text_train = pad_sequences(text_train, maxlen = maximum_text_length, padding='post')\n",
        "text_val = pad_sequences(text_val, maxlen = maximum_text_length, padding='post')\n",
        "\n",
        "x_vocab = x_tokenizer.num_words + 1\n",
        "\n",
        "# #tokenizer for summary\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(summary_train))\n",
        "\n",
        "count = 0\n",
        "for i in y_tokenizer.word_counts.items():\n",
        "  count = count + 1\n",
        "\n",
        "y_tokenizer = Tokenizer(num_words = count)\n",
        "y_tokenizer.fit_on_texts(list(summary_train))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "summary_train = y_tokenizer.texts_to_sequences(summary_train)\n",
        "summary_val = y_tokenizer.texts_to_sequences(summary_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "summary_train = pad_sequences(summary_train, maxlen = maximum_summary_length, padding='post')\n",
        "summary_val = pad_sequences(summary_val, maxlen = maximum_summary_length, padding='post')\n",
        "\n",
        "y_vocab = y_tokenizer.num_words + 1\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZL-wf7uLtJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "d68ecd41-4b67-454f-a7a9-3fd0bcce8149"
      },
      "source": [
        "#third party Attention \n",
        "#third party implementation layer\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n",
        "\n",
        "\n",
        "#model building\n",
        "\n",
        "K.clear_session()\n",
        "latent_dim = 500\n",
        "\n",
        "#Encoder \n",
        "encoder_inputs = Input(shape = (maximum_text_length,))\n",
        "\n",
        "#embedding layer\n",
        "encoder_embedding = Embedding(x_vocab, latent_dim,trainable = True)(encoder_inputs)\n",
        "\n",
        "#LSTM 1\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_output1, state_h1, state_c1 = encoder = encoder_lstm1(encoder_embedding)\n",
        "\n",
        "#LSTM 2\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, recurrent_dropout=0.3)\n",
        "encoder_output2, state_h2, state_c2 = encoder = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#LSTM 3\n",
        "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder = encoder_lstm3(encoder_output2)\n",
        "\n",
        "#Set up decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "decoder_embedding_layer = Embedding(y_vocab, latent_dim, trainable = True)\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences = True, return_state = True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_embedding, initial_state = [state_h, state_c])\n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "#Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs,attn_out])\n",
        "\n",
        "#Dense Layer\n",
        "decoder_dense = TimeDistributed(Dense(y_vocab, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 90)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 90, 500)      77943000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 90, 500), (N 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 90, 500), (N 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    23072000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 90, 500), (N 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 46144)  46190144    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 155,713,644\n",
            "Trainable params: 155,713,644\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MagxGbw9MGXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a4ab346a-f81a-4b88-ad98-2f64605055c4"
      },
      "source": [
        "#compile and run model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "history=model.fit([text_train,summary_train[:,:-1]], summary_train.reshape((summary_train.shape[0],summary_train.shape[1], 1))[:,1:] ,epochs=3,callbacks=[early_stopping],batch_size=512, validation_data=([text_val,summary_val[:,:-1]], summary_val.reshape(summary_val.shape[0],summary_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1171/1171 [==============================] - 3622s 3s/step - loss: 3.6030 - val_loss: 3.0829\n",
            "Epoch 2/3\n",
            "1171/1171 [==============================] - 3635s 3s/step - loss: 2.9666 - val_loss: 2.8385\n",
            "Epoch 3/3\n",
            "1171/1171 [==============================] - 3641s 3s/step - loss: 2.7524 - val_loss: 2.7229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOTJ2cbUMKmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "150e66aa-07f8-43db-969c-15fa7dab8360"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjjsNn-ZMMF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionary to convert the index to word \n",
        "reverse_summary_word_index=y_tokenizer.index_word\n",
        "reverse_text_word_index=x_tokenizer.index_word\n",
        "summary_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP4XVP_8MNpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Inference\n",
        "#Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "#Decoder \n",
        "#hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(maximum_text_length,latent_dim))\n",
        "\n",
        "#embeddings of the decoder sequence\n",
        "decoder_embedding2= decoder_embedding_layer(decoder_inputs) \n",
        "#setting initial states to the states from the previous time step for predicting next word\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedding2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense final output layer (softmax)\n",
        "# generate prob distribution over the summary vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZeH2lE8MO3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predicted(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    sequence = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    sequence[0, 0] = summary_word_index['starttoken']\n",
        "\n",
        "    quitt = False\n",
        "    predicted_summary = ''\n",
        "    while not quitt:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([sequence] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_summary_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='endtoken'):\n",
        "            predicted_summary += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'endtoken'  or len(predicted_summary.split()) >= (maximum_summary_length-1)):\n",
        "            quitt = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        sequence = np.zeros((1,1))\n",
        "        sequence[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return predicted_summary"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGicikQrMQI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "759a2226-482c-4b6f-b3a9-7c4408a9cc5d"
      },
      "source": [
        "def summary(summary):\n",
        "    original_sum = ''\n",
        "    for i in summary:\n",
        "        if((i!= 0 and i!= summary_word_index['starttoken']) and i!= summary_word_index['endtoken']):\n",
        "            original_sum = original_sum + reverse_summary_word_index[i]+' '\n",
        "    return original_sum\n",
        "\n",
        "def text(text):\n",
        "    original_text = ''\n",
        "    for i in text:\n",
        "        if(i!=0):\n",
        "            original_text = original_text + reverse_text_word_index[i]+' '\n",
        "    return original_text\n",
        "\n",
        "for i in range(50):\n",
        "  print(\"#\",i+1)\n",
        "  print(\"Text:\",text(text_val[i]))\n",
        "  print(\"Original summary:\",summary(summary_val[i]))\n",
        "  print(\"Predicted summary:\",predicted(text_val[i].reshape(1,maximum_text_length)))\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 1\n",
            "Text: first favor read books order come love every character meet book cannot tell much enjoyed two series witch central books story like little lagniappe enjoy modern witch books always loved good book family friends see best share joy lives lived together debora way combining host characters building one someone met love want know gift go next book cannot wait \n",
            "Original summary: i cannot stop reading debora geary \n",
            "Predicted summary:  another great read\n",
            "\n",
            "\n",
            "# 2\n",
            "Text: thought good story wish would bit longer though reminds us insecurities also reminds us worthy love respect good \n",
            "Original summary: hungry for love \n",
            "Predicted summary:  a good read\n",
            "\n",
            "\n",
            "# 3\n",
            "Text: incredible wisdom improving productivity recently gone self employed book invaluable sharpen working day make productive possible packed golden nuggets wisdom really successful people started pinning desk reminders \n",
            "Original summary: full of wisdom \n",
            "Predicted summary:  a must read for any success\n",
            "\n",
            "\n",
            "# 4\n",
            "Text: good news tea tastes great overpowering bleach taste like lipton box bought br bag thing box got exact one picture less colorful really matter also provides 0 71 ounces less tea total 2 84 less ounces boxes include 5 29 ounces tea instead 6 ounces box pictured usually expect get exact item one pictured give 3 stars reason otherwise great tea \n",
            "Original summary: great tasting tea \n",
            "Predicted summary:  good tea but not the price\n",
            "\n",
            "\n",
            "# 5\n",
            "Text: tastes great gives energy without jitters love product br however wish came sort resealable jar hard plastic container instead zip lock pouch zip lock ripped quit working awhile product fantastic crazy packaging \n",
            "Original summary: tastes great arrived in 2 days \n",
            "Predicted summary:  great product great price\n",
            "\n",
            "\n",
            "# 6\n",
            "Text: wanted something refreshing plain decaf ice tea wonderful tea tart without sugar way like really nice change added one cup decaf black tea good way even nice would like nice change without something find keeping night tart wonderful flavor color tea hubby puts sweetner loves usually drink tea saying something \n",
            "Original summary: fantastic ice tea \n",
            "Predicted summary:  great flavor and easy to make\n",
            "\n",
            "\n",
            "# 7\n",
            "Text: extremely short read blink eye miss something wouldnt even consider novella shortstory even pushing disappointed kade story short really like idea plot isnt enough meat potatoes characters likeable even dialogue reads like bad porn movie would think since kade heir pack would story tell editing bad blank page chapters made go back make sure whole book everything rushed characters made story really annoying times ordered worse books wont complain considering price dont know ms ryans series gets better say im tempted give next installment try \n",
            "Original summary: hopeful for the next \n",
            "Predicted summary:  not worth it\n",
            "\n",
            "\n",
            "# 8\n",
            "Text: read book really pulling main characters rediscover brought together first place \n",
            "Original summary: tough view of a marriage in decline \n",
            "Predicted summary:  a good read\n",
            "\n",
            "\n",
            "# 9\n",
            "Text: cookies amazing moist flavorful really satisfying cannot wait add teenagers lunches fall \n",
            "Original summary: quaker oatmeal cookies taste delicious \n",
            "Predicted summary:  best cookies ever\n",
            "\n",
            "\n",
            "# 10\n",
            "Text: great price using amazon subscription service bars satisfying snack hike bike even work highly recommend let sit around expire due chemicals used preserve \n",
            "Original summary: great deal i love these bars \n",
            "Predicted summary:  great product great price\n",
            "\n",
            "\n",
            "# 11\n",
            "Text: however story ends abruptly made wonder missing something rest seems pretty accurate description family holidays experienced \n",
            "Original summary: little book \n",
            "Predicted summary:  not for me\n",
            "\n",
            "\n",
            "# 12\n",
            "Text: end e book author asks leave review liked book others find good stories well found story ok still going write review sure rule main character iris broke maybe story would exciting followed rules story predictable romantic suspense get together married obviously together suspense bad guy survive course would highly trained retired military operatives read books red stone series breaking rules good example characters intrigue series would recommend reading danger next door red stone series instead \n",
            "Original summary: maybe she should have followed her rules \n",
            "Predicted summary:  a good read\n",
            "\n",
            "\n",
            "# 13\n",
            "Text: red wolfe part ii ella james5 starsthis another short part story glad jumped right continued right first part left chemistry red wolfe increases neither understand explain pull potential heal definitely looking forward next part story \n",
            "Original summary: even more steam than the first one \n",
            "Predicted summary:  i want more\n",
            "\n",
            "\n",
            "# 14\n",
            "Text: loved cute inexpensive gift ideas authors come 8217 great range handmade crafts gift recipes heart store bought gift absolutely loved greatest memories gift idea well tree limb coasters java jackets gift cute kids 8217 project look forward trying kids christmas break lots great photos help visualize project great book ideas \n",
            "Original summary: homemade christmas gifts \n",
            "Predicted summary:  great little book\n",
            "\n",
            "\n",
            "# 15\n",
            "Text: hfcs like many formulas thought powder would pain first much convenient travel storage price amazon subscribe save like 25 lower whole foods \n",
            "Original summary: it is good \n",
            "Predicted summary:  good formula good price\n",
            "\n",
            "\n",
            "# 16\n",
            "Text: bought gift 18yr old daughter loves uses day everyday works well far surfing etc hopefully get used college soon definitely worth price complaint emailed seller couple basic questions never answered disappointing \n",
            "Original summary: good for the price \n",
            "Predicted summary:  great for a gift\n",
            "\n",
            "\n",
            "# 17\n",
            "Text: great quality flavoured peach black tea love used strictly buy bentleys br stopped selling peach flavor great substitute little br expensive well worth \n",
            "Original summary: shash premium peach black tea \n",
            "Predicted summary:  great tasting tea\n",
            "\n",
            "\n",
            "# 18\n",
            "Text: books series far least favorite definitely say dissapointed thought three books author would definitely gone bang always write reviews better know hang hat series overall rate book 3 felt rushed like drea delgado put together day heck smokes character tania soooo damn weak mean come nico may scary damn chick self worth mean really \n",
            "Original summary: loyalty and respect 4 \n",
            "Predicted summary:  i am not disappointed\n",
            "\n",
            "\n",
            "# 19\n",
            "Text: ok maybe fault expecting something different received enough rabbits allready need place keep \n",
            "Original summary: thought i was ordering a rabbit hole \n",
            "Predicted summary:  not what i expected\n",
            "\n",
            "\n",
            "# 20\n",
            "Text: good book kids especially christmas merry christmas kids trying come twenty words hard \n",
            "Original summary: great for kids \n",
            "Predicted summary:  a christmas story\n",
            "\n",
            "\n",
            "# 21\n",
            "Text: whole wheat pasta al dente texture white pasta taste also similar white pasta whole wheat pasta ever truly liked \n",
            "Original summary: best whole wheat \n",
            "Predicted summary:  best pasta ever\n",
            "\n",
            "\n",
            "# 22\n",
            "Text: high school english teacher told read class list told read three times like movie candyman suppose right best shakespearean dramas contains enough comedy perhaps best shakespearean comedies also \n",
            "Original summary: one of the best by the author \n",
            "Predicted summary:  the best popcorn ever\n",
            "\n",
            "\n",
            "# 23\n",
            "Text: thank brenda sending arc book finish reading book one content ending cliffhangers course mind reading ryke kate glad brenda gave gave us sweet couple captive continues story ryke kate expect story take seems like kate ups downs strong wanted always little bit weak ryke like always love ryke book amazing go get copy read cannot wait reak luke story \n",
            "Original summary: captivated by this story \n",
            "Predicted summary:  i love this series\n",
            "\n",
            "\n",
            "# 24\n",
            "Text: good story line really liked layla brian story got see little jack rachel story well book adult read \n",
            "Original summary: i liked it very much \n",
            "Predicted summary:  the rancher takes a bride\n",
            "\n",
            "\n",
            "# 25\n",
            "Text: nicely done think author fine job book enjoyed kids couple different age groups opinion \n",
            "Original summary: nice kids book \n",
            "Predicted summary:  a good read\n",
            "\n",
            "\n",
            "# 26\n",
            "Text: drip machine produces brown water coffee br br stove top espresso machine weak smooth palatable tasted like black tea coffee br br immersion brew smooth thick strong huge buzz pour 1 quart hot water 3 pods let steep 15 minutes caffeine leave pods water 5 12 hours br br br bottom line pods need stay water longer conventional methods much way tea bags need time steep \n",
            "Original summary: tastes great when brewed like tea \n",
            "Predicted summary:  smells like tea\n",
            "\n",
            "\n",
            "# 27\n",
            "Text: wonderful story lucian suck want escape say book boyfriend alpha male desire romance read story come \n",
            "Original summary: alpha male great read \n",
            "Predicted summary:  a great read\n",
            "\n",
            "\n",
            "# 28\n",
            "Text: start day 5 hour energy arrive month subscription best way save money order 3 boxes subscription save consistently store prices \n",
            "Original summary: best way to buy 5 hour energy \n",
            "Predicted summary:  great product great price\n",
            "\n",
            "\n",
            "# 29\n",
            "Text: far one better flavored coffee brooklyn beans would definitely recommend one \n",
            "Original summary: great cup of coffee \n",
            "Predicted summary:  best coffee ever\n",
            "\n",
            "\n",
            "# 30\n",
            "Text: purchased love try read verses day love way breaks bible especially someone like know bible definately worth \n",
            "Original summary: way to get to know the bible \n",
            "Predicted summary:  great bible bible\n",
            "\n",
            "\n",
            "# 31\n",
            "Text: first paprika used come grocery store products frame reference said wow amazing flavor aware paprika capable palette added quarter teaspoon small pot fresh picked lima beans quartered tomatoes hock bone tablespoon grey poupon mustard say wish made next day leftovers br br smoky slightly sweet sooo delicious cannot wait try dishes also looking forward trying paprikas line \n",
            "Original summary: not your grocery store paprika \n",
            "Predicted summary:  the best hot sauce ever\n",
            "\n",
            "\n",
            "# 32\n",
            "Text: another great mystery elizabeth craig love myrtle miles cannot decide like best story characters kept guessing kept reading \n",
            "Original summary: love these books \n",
            "Predicted summary:  another great mystery\n",
            "\n",
            "\n",
            "# 33\n",
            "Text: story book entertains cute ya book really enjoyed characters story good writing entertainment enjoy \n",
            "Original summary: it is a good book \n",
            "Predicted summary:  a good read\n",
            "\n",
            "\n",
            "# 34\n",
            "Text: great source nutrition love packaging easy dispense make messes opened test baby adorable baby caleb aged 5 months loved think would eat every meal think liked many failed attempts brands green vegetable child may pre programmed picky eating parents terribly picky eaters yet truly loved kiddo eat whole package one sitting asks total hit try \n",
            "Original summary: only green food he eats \n",
            "Predicted summary:  great for baby\n",
            "\n",
            "\n",
            "# 35\n",
            "Text: chose last story end quite wished knew got sister home \n",
            "Original summary: what i think \n",
            "Predicted summary:  the end of a story\n",
            "\n",
            "\n",
            "# 36\n",
            "Text: love syrup flavoring sugar free drinks add diet soda sugar free non carbonated drink mixes like crystal light punch drops create cherry coke cherry limeade etc \n",
            "Original summary: perfect for flavoring diet drinks \n",
            "Predicted summary:  great tasting soda\n",
            "\n",
            "\n",
            "# 37\n",
            "Text: great story great author love book anything animals best friends \n",
            "Original summary: the five kisses \n",
            "Predicted summary:  great story and great characters\n",
            "\n",
            "\n",
            "# 38\n",
            "Text: nice quick read liked felt something missing maybe epilogue want give anything away years later cole syd met fell love matter days years later maybe wanted story details filled etc last chapter epilogue 3 different relationships mentioned someone else gave 3 5 stars think would agree enjoy enough look books author \n",
            "Original summary: a nice story \n",
            "Predicted summary:  a quick read\n",
            "\n",
            "\n",
            "# 39\n",
            "Text: new frustration free packaging k cups terrific thank amazon com gloria jean hazelnut one favorites flavored coffee second butter toffee however wanting bold wake going please pretty mild blend someone make really bold flavored coffee surely possible big fan emeril big easy morning brew later day dinner gloria jean hazlenut perfect \n",
            "Original summary: no frustration love the new packaging \n",
            "Predicted summary:  great flavor and aroma\n",
            "\n",
            "\n",
            "# 40\n",
            "Text: good advertised earthy liked much always nice fine robust decaffeinated tea \n",
            "Original summary: red bush tea \n",
            "Predicted summary:  good cup of decaf\n",
            "\n",
            "\n",
            "# 41\n",
            "Text: say fan energy drink initials r b moo huge fan flavor perfect match hooked never spend dime store name brand \n",
            "Original summary: energy drink flavor is spot on \n",
            "Predicted summary:  love this stuff\n",
            "\n",
            "\n",
            "# 42\n",
            "Text: personally think best one series loved raccoon lilah perfectly wonderfully crazy kind crazy would mind friend cannot say many heroines rex plain old sweet add daughter loved whole package would highly recommend lynn books one definitely going reread shelf \n",
            "Original summary: such a good book \n",
            "Predicted summary:  i love this series\n",
            "\n",
            "\n",
            "# 43\n",
            "Text: according research online coconut oil work great hair oil reported penetrate hair shaft leaves hair soft moistened use oil pre conditioner 30 min longer heat followed shampoo shampoo apply coconut oil oils seal oil hair product cost effective natural importantly work \n",
            "Original summary: best oil for hair \n",
            "Predicted summary:  hair oil is great\n",
            "\n",
            "\n",
            "# 44\n",
            "Text: love flavor coffee keurig machine subtle sweet husband love coffee super sweet prefer mine black enjoy without adding anything definitely think particular item great value couple people make coffee daily really go k cups product keeps us stocked arrived one two damaged transit really bother removed broken cups transferred rest k cup staging area definitely good buy \n",
            "Original summary: love this coffee \n",
            "Predicted summary:  great coffee great price\n",
            "\n",
            "\n",
            "# 45\n",
            "Text: everyone tried far say flavor excellent br also price amazon reasonable pod brewing br system availability pods local stores rapidly br diminishing \n",
            "Original summary: wolfgang puck coffee pods \n",
            "Predicted summary:  great coffee great price\n",
            "\n",
            "\n",
            "# 46\n",
            "Text: although subtitle retelling expected original material quite predictable many levels somewhat ludicrous others read conan doyle crichton saltzman believe liked crichton best good book great book \n",
            "Original summary: more retelling than expected \n",
            "Predicted summary:  a great read\n",
            "\n",
            "\n",
            "# 47\n",
            "Text: tired trying different brands work coffee club purchased one everybody likes keep freezer everytime open aroma coffee fills room also purchased couple american brands review try know one winner way paid 10 one safeway \n",
            "Original summary: great coffee cheaper at stores \n",
            "Predicted summary:  great coffee great price\n",
            "\n",
            "\n",
            "# 48\n",
            "Text: high hopes could finish book totally recommend difference 34 fun 34 right 34 silly 34 \n",
            "Original summary: not that good \n",
            "Predicted summary:  not my cup of tea\n",
            "\n",
            "\n",
            "# 49\n",
            "Text: perhaps light refreshing minty taste mojito flavor favorite appletini margarita mojito mixes margarita mix lacking limey zip appletini good great refreshing thirst quenching felt like real treat \n",
            "Original summary: our favorite out of all the moctails \n",
            "Predicted summary:  good light drink\n",
            "\n",
            "\n",
            "# 50\n",
            "Text: vey sweet age play story anna young innocent noah really good harsh situations story impossible story written diary format nice change would liked see noah thought process \n",
            "Original summary: sweet age play \n",
            "Predicted summary:  a sweet story\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7CH4sWdMTBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#text = Amazing I never read the Harry potter books but was looking for something fantasy esque to read. Enter this book which kept me captivated, on the edge of my seat and emotional all throughout. Go into this book blind trust me, you'll love what you read\n",
        "\n",
        "text = input(\"Text: \")\n",
        "\n",
        "clean = content_cleaner(text)\n",
        "\n",
        "accepted = []\n",
        "accepted.append(clean)\n",
        "\n",
        "accepted = list(map(lambda x: 'starttoken '+ x + ' endtoken', accepted))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "accepted = x_tokenizer.texts_to_sequences(accepted)\n",
        "#ensures all sequences in the list have the same length\n",
        "accepted = pad_sequences(accepted, maxlen = maximum_text_length, padding='post')\n",
        "\n",
        "print(\"Predicted: \",predicted(accepted[0].reshape(1,maximum_text_length)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}